{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a829cda-ce2b-43c1-a98d-d363c9790b2f",
   "metadata": {},
   "source": [
    "# Stereo Images Parallax Estimation using RIPOC image correlation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47634c-c8cf-4d42-8b24-d61d578c56ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.color import rgba2rgb, rgb2gray\n",
    "from skimage.filters import meijering, sato, frangi, hessian\n",
    "from skimage.util import dtype_limits\n",
    "# from matplotlib.image import imread\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "## affine変換による並行回転拡大\n",
    "##########\n",
    "def image_affine(img_src, x, y, angle = 0, scale = 1.0):\n",
    "    h, w = img_src.shape[:2]\n",
    "\n",
    "    # 回転中心\n",
    "    center = (w/2, h/2)\n",
    "    # 回転・拡大行列 (angle は degree(度), scale は 1.0 = 100%として指定)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    # 並行移動成分を追加\n",
    "    M[0][2] -= x\n",
    "    M[1][2] -= y\n",
    "    img_dst = cv2.warpAffine(img_src, M, (w, h))\n",
    "    return img_dst\n",
    "    \n",
    "## convert gray image by percentile\n",
    "##########\n",
    "def gray_image(inimg, percentile = -1):\n",
    "    if(inimg.ndim == 3):\n",
    "        srcimg = cv2.cvtColor(inimg, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        srcimg = inimg.copy()\n",
    "    dstimg = np.zeros(srcimg.shape)\n",
    "    maxvalue = np.max(srcimg)\n",
    "    minvalue = np.min(srcimg)\n",
    "    if(percentile > 0):\n",
    "        maxvalue = np.percentile(srcimg, percentile)\n",
    "        srcimg = np.clip(srcimg, a_min = minvalue, a_max = maxvalue)\n",
    "        # print(\"max = %.1f, min = %.1f\" % (maxvalue, minvalue))\n",
    "    if(maxvalue <= minvalue):\n",
    "        maxvalue = 1\n",
    "        minvalue = 0\n",
    "    dstimg = cv2.convertScaleAbs(srcimg - minvalue, alpha = 255 / (maxvalue - minvalue), beta = 0)\n",
    "    dstimg = dstimg.astype(np.uint8)\n",
    "    return dstimg\n",
    "\n",
    "## color 画像に変換 (convert color image)\n",
    "##########\n",
    "def color_image(srcimg):\n",
    "    # print(img.shape)\n",
    "    \n",
    "    if(srcimg.ndim == 3):\n",
    "        dstimg = srcimg\n",
    "    else:\n",
    "        gray = srcimg\n",
    "        if(srcimg.dtype != \"uint8\"):\n",
    "            gray = gray_image(srcimg)\n",
    "        dstimg = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "    return dstimg\n",
    "\n",
    "## get keypoints\n",
    "##########\n",
    "def get_keypoints(img, flag_negative=False, flag_resize=True, flag_edge=True):\n",
    "    \n",
    "    ## size and planes\n",
    "    height, width, planes = img.shape\n",
    "    \n",
    "    ## convert gray scale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if(flag_negative):\n",
    "        img_gray = 255 - img_gray\n",
    "    \n",
    "    ## Hisgram equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    img_clahe = clahe.apply(img_gray)\n",
    "    # img_clahe = cv2.equalizeHist(img_gray)\n",
    "    # img_clahe = img_gray.copy()\n",
    "    \n",
    "    ## Resize\n",
    "    img_resized = img_clahe.copy()\n",
    "    if(flag_resize):\n",
    "        img_resized = cv2.resize(img_resized, (int(width / 2), int(height / 2)))\n",
    "    \n",
    "    ## DeNoising\n",
    "    # NOISEBLOCKSIZE = 20\n",
    "    NOISEBLOCKSIZE = 30\n",
    "    img_denoised = cv2.fastNlMeansDenoising(img_resized, h=NOISEBLOCKSIZE)\n",
    "    # img_denoised = img_resized.copy()\n",
    "    \n",
    "    ## filtered\n",
    "    img_filtered = img_denoised.copy()\n",
    "    if(flag_edge):\n",
    "        # img_filtered = gray_image(frangi(img_denoised))\n",
    "        # img_filtered = clahe.apply(gray_image(frangi(img_denoised)))\n",
    "        # img_filtered = gray_image(meijering(img_denoised))\n",
    "        # img_filtered = clahe.apply(gray_image(meijering(img_denoised)))\n",
    "        # img_filtered = gray_image(sato(img_denoised))\n",
    "        # img_filtered = cv2.Canny(img_denoised, 0, 200)\n",
    "        # img_filtered = cv2.morphologyEx(cv2.Canny(img_denoised, 0, 100), cv2.MORPH_CLOSE, np.ones((5,5),np.uint8))\n",
    "        # img_filtered = cv2.Laplacian(img_denoised, -1, ksize=3) \n",
    "        img_filtered = clahe.apply(cv2.Laplacian(img_denoised, -1, ksize=3))\n",
    "    \n",
    "    ## Initiate SIFT or AKAZE detector *select one*\n",
    "    ## find the keypoints and descriptors with SIFT or AKAZE\n",
    "    # detector = cv2.AKAZE_create()\n",
    "    # detector = cv2.BRISK_create()\n",
    "    # detector = cv2.FastFeatureDetector_create() # not implemented\n",
    "    # detector = cv2.KAZE_create()\n",
    "    detector = cv2.ORB_create()\n",
    "    # detector = cv2.SIFT_create(1000)\n",
    "    # detector = cv2.SIFT_create()\n",
    "    # detector = cv2.xfeatures2d.SURF_create() # patented, not implemented\n",
    "    # detector = cv2.xfeatures2d.LATCH_create() # not implemented\n",
    "    kp, des = detector.detectAndCompute(img_filtered, None)\n",
    "    img_key = cv2.drawKeypoints(img_filtered, kp, None, flags=4)\n",
    "    \n",
    "    return kp, des, img_resized, img_denoised, img_clahe, img_filtered, img_key\n",
    "\n",
    "## RIPOC function\n",
    "## Obtain parameters for translation (x, y), rotation (angle), and scaling (scale)\n",
    "## with response, and some processing images\n",
    "##########\n",
    "def RIPOCfunc(imgR, imgM, flag_Debug=True):\n",
    "    ## flag_Debug = True  ## display step-by-step images for debug\n",
    "\n",
    "    # 画像読み込み\n",
    "    ref_img = imgR\n",
    "    tgt_img = imgM\n",
    "\n",
    "    # Numpy配列に変換\n",
    "    ref_img_gray = np.array(ref_img,dtype=np.float64)\n",
    "    tgt_img_gray = np.array(tgt_img,dtype=np.float64)\n",
    "\n",
    "    # 画像サイズ定義\n",
    "    h, w = ref_img_gray.shape\n",
    "    center = (w/2, h/2)\n",
    "\n",
    "    # 窓関数定義\n",
    "    hunning_y = np.hanning(h)\n",
    "    hunning_x = np.hanning(h)\n",
    "    hunning_w = hunning_y.reshape(h, 1)*hunning_x\n",
    "\n",
    "    # フーリエ変換\n",
    "    ref_img_fft = np.fft.fftshift(np.log(np.abs(np.fft.fft2(ref_img_gray*hunning_w))))\n",
    "    tgt_img_fft = np.fft.fftshift(np.log(np.abs(np.fft.fft2(tgt_img_gray*hunning_w))))\n",
    "\n",
    "    # 対数極座標変換 (lanczos法補間)\n",
    "    l = np.sqrt(w*w + h*h)\n",
    "    m = l/np.log(l)\n",
    "    flags = cv2.INTER_LANCZOS4 + cv2.WARP_POLAR_LOG\n",
    "    ref_img_pol = cv2.warpPolar(ref_img_fft, (w, h), center, m, flags)\n",
    "    tgt_img_pol = cv2.warpPolar(tgt_img_fft, (w, h), center, m, flags)\n",
    "\n",
    "    # 位相限定相関法\n",
    "    (x, y), response = cv2.phaseCorrelate(ref_img_pol, tgt_img_pol, hunning_w)\n",
    "\n",
    "    # affine変換による平行移動\n",
    "    angle = y*360/h\n",
    "    scale = (np.e)**(x/m)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    tgt_img_affine = cv2.warpAffine((tgt_img_gray), M, (w, h))\n",
    "\n",
    "    # 位相限定相関法\n",
    "    (x, y), response = cv2.phaseCorrelate(ref_img_gray, tgt_img_affine)\n",
    "\n",
    "    #位相限定相関法の返り値から画像を生成\n",
    "    M[0][2] -= x\n",
    "    M[1][2] -= y\n",
    "    dst = cv2.warpAffine(tgt_img, M, (w, h))\n",
    "\n",
    "    if(flag_Debug):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.ylabel('input')\n",
    "        plt.xlabel('reference')\n",
    "        plt.imshow(ref_img)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.xlabel('target')\n",
    "        plt.imshow(tgt_img)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.ylabel('FFT')\n",
    "        plt.xlabel('reference')\n",
    "        plt.imshow(ref_img_fft)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.xlabel('target')\n",
    "        plt.imshow(tgt_img_fft)\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.ylabel('polar')\n",
    "        plt.xlabel('reference')\n",
    "        plt.imshow(ref_img_pol)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.xlabel('target')\n",
    "        plt.imshow(tgt_img_pol)\n",
    "        plt.show()\n",
    "        \n",
    "        px = pz = np.linspace(-100, 100, h)\n",
    "        px , pz = np.meshgrid(px, pz)\n",
    "        img = ref_img_pol\n",
    "        py = img\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter3D(np.ravel(px), np.ravel(pz), np.ravel(py),s=10,marker='.',c=img)\n",
    "        ax.set_title(\"image\")\n",
    "        plt.show()\n",
    "\n",
    "    return x, y, angle, scale, response, tgt_img_affine, dst\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3552fdca-6ad5-4ec7-bc87-91d12afd058e",
   "metadata": {},
   "source": [
    "# RDS to Anaglyph 3D - RDS parallax estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e4830-980b-42ba-adbb-24098dadba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "##\n",
    "## draw triangle\n",
    "##\n",
    "def triangle_draw(img, c = (0, 0, 0), ox = 70, oy = 70, d = 0, s = 10, text_flag = False):\n",
    "    ax =  s * np.cos(( 30 + d) * np.pi / 180) + ox\n",
    "    ay = -s * np.sin(( 30 + d) * np.pi / 180) + oy\n",
    "    bx =  s * np.cos((-30 + d) * np.pi / 180) + ox\n",
    "    by = -s * np.sin((-30 + d) * np.pi / 180) + oy\n",
    "    cx =  (s) * np.cos(d * np.pi / 180) + ox\n",
    "    cy = -(s) * np.sin(d * np.pi / 180) + oy\n",
    "    pts = np.array([(int(ox), int(oy)), (int(ax), int(ay)), (int(bx), int(by))])\n",
    "    img = cv2.polylines(img, [pts], True, c, thickness=3)\n",
    "    img = cv2.fillConvexPoly(img, pts, (0, 0, 0))\n",
    "    if(text_flag):\n",
    "        fontScale = 0.5\n",
    "        fontColor = (255, 255, 255)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = '%03d' % (d)\n",
    "        img = cv2.putText(img, text, (int(cx + 1), int(cy + 1)), font, fontScale, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "        img = cv2.putText(img, text, (int(cx + 0), int(cy + 0)), font, fontScale, fontColor, 1, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "## 【ガンマ補正の公式】\n",
    "## Gamma correction\n",
    "##   Y = 255(X/255)**(1/γ)\n",
    "## 【γの設定方法】\n",
    "## How to set Y parameter\n",
    "##   ・γ>1の場合：画像が明るくなる / case Y>1: image become brighter\n",
    "##   ・γ<1の場合：画像が暗くなる / case Y<1: image become darker\n",
    "def gamma_correction(img, gamma = 1.6):\n",
    "    # ガンマ変換用の数値準備 \n",
    "    # gamma     = 3.0                               # γ値を指定\n",
    "    img2gamma = np.zeros((256,1),dtype=np.uint8)  # ガンマ変換初期値\n",
    "    # 公式適用\n",
    "    for i in range(256):\n",
    "        img2gamma[i][0] = 255 * (float(i)/255) ** (1.0 /gamma)\n",
    "    # 読込画像をガンマ変換\n",
    "    gamma_img = cv2.LUT(img, img2gamma)\n",
    "    return gamma_img\n",
    "\n",
    "##\n",
    "## 画像の切り出し\n",
    "## crop image\n",
    "##\n",
    "def image_crop(img_src, x, y, l):\n",
    "    h, w = img_src.shape[:2]\n",
    "    cx = int(x)\n",
    "    cy = int(y)\n",
    "    cx1 = int(cx - l/2)\n",
    "    cx2 = int(cx + l/2)\n",
    "    cy1 = int(cy - l/2)\n",
    "    cy2 = int(cy + l/2)\n",
    "    if(cx1 < 0):\n",
    "        cx1 = 0\n",
    "        cx2 = cx1 + l\n",
    "    if(cx2 >= w):\n",
    "        cx2 = w - 1\n",
    "        cx1 = cx2 - l\n",
    "    if(cy1 < 0):\n",
    "        cy1 = 0\n",
    "        cy2 = cy1 + l\n",
    "    if(cy2 >= h):\n",
    "        cy2 = h - 1\n",
    "        cy1 = cy2 - l\n",
    "    img_dst = img_src[cy1:cy2, cx1:cx2]\n",
    "    return img_dst\n",
    "\n",
    "##\n",
    "## affine変換による並行回転拡大\n",
    "## Parallel movement, rotation, and zoom by affine transformation\n",
    "##\n",
    "def image_affine(img_src, x, y, angle = 0, scale = 1.0):\n",
    "    h, w = img_src.shape[:2]\n",
    "\n",
    "    # 回転中心 center of rotation\n",
    "    center = (w/2, h/2)\n",
    "    # 回転・拡大行列 (angle は degree(度), scale は 1.0 = 100%として指定)\n",
    "    # rotation and zoom matrix (unit of angle is degree, scale 1.0 means 100%)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    # 並行移動成分を追加\n",
    "    # Added parallel moving components\n",
    "    M[0][2] -= x\n",
    "    M[1][2] -= y\n",
    "    img_dst = cv2.warpAffine(img_src, M, (w, h))\n",
    "    return img_dst\n",
    "\n",
    "##########################################################################\n",
    "### Main routine\n",
    "###\n",
    "\n",
    "## when image saves, set True\n",
    "flag_image_save = False\n",
    "\n",
    "## to find how many parallax (focus candidate) \n",
    "max_n_paralax = 1\n",
    "\n",
    "## set RDS file name\n",
    "rds_file = 'images/RDS/16_100_ROBO.png'\n",
    "#rds_file = 'images/RDS/20_150_CUBE.png'\n",
    "#rds_file = 'images/RDS/25_160_EARTH.png'\n",
    "\n",
    "## If the parallax estimation fails, try changing the window size (l) and height position (r). \n",
    "## window size of block matching area\n",
    "l = 120\n",
    "## height position (ratio) of sliding window\n",
    "r = 1/2\n",
    "\n",
    "img_src = cv2.imread(rds_file)\n",
    "h, w = img_src.shape[:2]\n",
    "y1 = int(h * r)\n",
    "\n",
    "flag_resize = False\n",
    "flag_negative = False\n",
    "flag_edge = False\n",
    "\n",
    "#for x1 in range(int(l/2), int(w - l/2) - 1):\n",
    "dif = []\n",
    "mov = []\n",
    "res = []\n",
    "zero_dif = []\n",
    "zero_mov = []\n",
    "zero_res = []\n",
    "\n",
    "for x1 in [int(w/2)]:\n",
    "    imgR_org = image_crop(img_src, x1, y1, l)\n",
    "    GRAY_PERCENTILE = 98\n",
    "    imgR_gray = gray_image(imgR_org, GRAY_PERCENTILE)\n",
    "    imgR_color = color_image(imgR_gray)\n",
    "    kpR, desR, imgR_resized, imgR_denoise, imgR_clahe, imgR_filtered, imgR_key = get_keypoints(imgR_color, flag_negative, flag_resize, flag_edge)\n",
    "\n",
    "    y2 = y1\n",
    "    for x2 in range(x1 + 1, int(w - l/2)):\n",
    "        imgM_org = image_crop(img_src, x2, y2, l)\n",
    "        # imgM_org = cv2.resize(imgM_org, imgR_org.shape)\n",
    "        GRAY_PERCENTILE = 98\n",
    "        imgM_gray = gray_image(imgM_org, GRAY_PERCENTILE)\n",
    "        imgM_color = color_image(imgM_gray)\n",
    "        kpM, desM, imgM_resized, imgM_denoise, imgM_clahe, imgM_filtered, imgM_key = get_keypoints(imgM_color, flag_negative, flag_resize, flag_edge)\n",
    "        \n",
    "        x, y, angle, scale, response, imgM_affine, imgM_result = RIPOCfunc(imgR_filtered, imgM_filtered, flag_Debug=False)\n",
    "        # print(\"refer(%d, %d), differ=%d, move(%.1f, %.1f), angle=%.3f, scale=%.3f, response=%.3f\" % (x1, y1, x2 - x1, x, y, angle, scale, response))\n",
    "        dif.append(x2 - x1)\n",
    "        mov.append(x)\n",
    "        res.append(response)\n",
    "        \n",
    "        #if(np.abs(x) < 1):\n",
    "        #    zero_mov.append(x)\n",
    "        #    zero_dif.append(x2 - x1)\n",
    "        #    zero_res.append(response)\n",
    "        \n",
    "        cv2.imshow('Reference'    , imgR_filtered)\n",
    "        cv2.imshow('Moving Target', imgM_filtered)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "for i in range(len(mov) - 1):\n",
    "    if(((mov[i] >= 0 and mov[i + 1] <= 0) or \n",
    "         (mov[i] <= 0 and mov[i + 1] >= 0)) and \n",
    "        np.abs(mov[i] - mov[i + 1]) < 5 and \n",
    "        res[i] > 0.1):\n",
    "        zero_mov.append(mov[i])\n",
    "        zero_dif.append(dif[i])\n",
    "        zero_res.append(res[i])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.xlabel('Difference [pix]')\n",
    "plt.ylabel('Moving [pix]')\n",
    "# plt.ylim(0, 1.2)\n",
    "# plt.xlim(-1,1)\n",
    "ymax = max(np.abs(mov))\n",
    "ymax = 60 if(ymax > 60) else ymax\n",
    "#ymax = 200 if(ymax > 200) else ymax\n",
    "plt.xlim(0, int(w / 2))\n",
    "plt.ylim(-ymax, ymax)\n",
    "plt.plot(dif, mov)\n",
    "plt.plot(zero_dif, zero_mov, 'o')\n",
    "plt.grid()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.xlabel('Difference [pix]')\n",
    "plt.ylabel('Response')\n",
    "plt.xlim(0, int(w / 2))\n",
    "# plt.ylim(0, 1.2)\n",
    "plt.plot(dif, res)\n",
    "plt.plot(zero_dif, zero_res, 'o')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"diff    :\", zero_dif)\n",
    "print(\"moving  :\", zero_mov)\n",
    "print(\"response:\", zero_res)\n",
    "\n",
    "color = [(128, 128, 128),\n",
    "         (255, 128, 128),\n",
    "         (128, 128, 255),\n",
    "         (255, 128, 255),\n",
    "         (128, 192, 128),\n",
    "         (255, 255, 128),\n",
    "         (128, 255, 255),\n",
    "         (255, 255, 255)]\n",
    "\n",
    "if(len(zero_dif) > 0):\n",
    "    n = 0\n",
    "    c = 1\n",
    "    pd_list = []\n",
    "    img_dot = img_src.copy()\n",
    "    for d in zero_dif:\n",
    "        x1 = int(w / 2 - d / 2)\n",
    "        x2 = int(w / 2 + d / 2)\n",
    "        y1 = 32 if (n % 2 == 0) else (h - 32) # int(h/2)\n",
    "        y2 = y1\n",
    "        if(n % 4 < 2):\n",
    "            cv2.circle(img_dot, (x1, y1), 8, color[c], thickness= 3)\n",
    "            cv2.circle(img_dot, (x1, y1), 8, (0,0,0) , thickness=-1)\n",
    "            cv2.circle(img_dot, (x2, y2), 8, color[c], thickness= 3)\n",
    "            cv2.circle(img_dot, (x2, y2), 8, (0,0,0) , thickness=-1)\n",
    "        else:\n",
    "            triangle_draw(img_dot, c=color[c], ox=x1, oy=y1-8, d=-90, s=16) \n",
    "            triangle_draw(img_dot, c=color[c], ox=x2, oy=y2-8, d=-90, s=16) \n",
    "            #cv2.rectangle(img_dot, (x1 - 8, y1 - 8), (x1 + 8, y1 + 8), color[c] , thickness=  3) \n",
    "            #cv2.rectangle(img_dot, (x1 - 8, y1 - 8), (x1 + 8, y1 + 8), (0, 0, 0), thickness= -1) \n",
    "            #cv2.rectangle(img_dot, (x2 - 8, y2 - 8), (x2 + 8, y2 + 8), color[c] , thickness=  3) \n",
    "            #cv2.rectangle(img_dot, (x2 - 8, y2 - 8), (x2 + 8, y2 + 8), (0, 0, 0), thickness= -1) \n",
    "        \n",
    "        c = (c + 1) & 7\n",
    "        n = n + 1\n",
    "        pd_list.append(d)\n",
    "        if(n >= max_n_paralax):\n",
    "            break\n",
    "    img_rgb = cv2.cvtColor(img_dot, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    if(flag_image_save):\n",
    "        file_body = os.path.splitext(rds_file)[0]\n",
    "        img_dot_file = file_body + \"_dot.png\"\n",
    "        cv2.imwrite(img_dot_file, img_dot)\n",
    "        \n",
    "    for pd in pd_list:\n",
    "        img_gray = cv2.cvtColor(img_src, cv2.COLOR_BGR2GRAY)\n",
    "        # img_gamma = gamma_correction(img_gray, 0.8)\n",
    "        img_b, img_g, img_r = cv2.split(img_src)\n",
    "        img_b = image_affine(img_b   ,  pd/2, 0)\n",
    "        img_g = image_affine(img_g   ,  pd/2, 0)\n",
    "        img_r = image_affine(img_gray, -pd/2, 0)\n",
    "        imgMerge_color = cv2.merge((img_b, img_g, img_r))\n",
    "        imgMerge_rgb   = cv2.cvtColor(imgMerge_color, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(imgMerge_rgb)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.show()\n",
    "    \n",
    "        img_gray = cv2.cvtColor(img_src, cv2.COLOR_BGR2GRAY)\n",
    "        img_b = image_affine(img_gray,  pd/2, 0)\n",
    "        img_r = image_affine(img_gray, -pd/2, 0)\n",
    "        height, width = img_gray.shape[:2]\n",
    "        blank = np.zeros((height, width, 1), np.uint8)\n",
    "        imgMerge_rb  = cv2.merge((img_b, blank, img_r))\n",
    "        imgMerge_rgb = cv2.cvtColor(imgMerge_rb, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(imgMerge_rgb)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.show()\n",
    "    \n",
    "        if(flag_image_save):\n",
    "            # img_right = image_affine(img_src,  pd/2, 0)\n",
    "            # img_left  = image_affine(img_src, -pd/2, 0)\n",
    "            # img_right_file = file_body + \"_%03d_right.png\" % (pd)\n",
    "            # img_left_file  = file_body + \"_%03d_left.png\"  % (pd)\n",
    "            # cv2.imwrite(img_right_file, img_right)\n",
    "            # cv2.imwrite(img_left_file , img_left )\n",
    "            img_color_file = file_body + \"_%03d_color.png\" % (pd)\n",
    "            img_rb_file    = file_body + \"_%03d_rb.png\"    % (pd)\n",
    "            cv2.imwrite(img_color_file, imgMerge_color)\n",
    "            cv2.imwrite(img_rb_file   , imgMerge_rb)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d178c3d-93d3-487a-bab9-78aa6e82f228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
